# Full fine-tuning - no LoRA, no quant, no flash (10 steps)
# VRAM: ~14-16 GB
data:
  dataset_path: "/workspace/project/data/radiology_mini"
  do_train: true
  do_eval: false

model:
  name: "Qwen/Qwen2.5-VL-3B-Instruct"
  tune_vision: false
  tune_mlp: true
  tune_llm: false

training:
  output_dir: "./outputs/debug_full"
  max_steps: 10
  batch_size: 1
  gradient_accumulation_steps: 1
  learning_rate: 1.0e-5
  warmup_steps: 2
  logging_steps: 2
  save_steps: 10

  lora:
    enabled: false

  quantization:
    enabled: false

  optimization:
    flash_attention: false
    gradient_checkpointing: true
    bf16: true

ray:
  num_workers: 1
  use_gpu: true
