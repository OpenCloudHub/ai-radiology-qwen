[project]
name = "ai-radiology-qwen"
version = "0.1.0"
description = "Vision-language model training and serving with Qwen, Ray, and MLflow"
readme = "README.md"
requires-python = ">=3.12,<3.13"
dependencies = [
    "pydantic-settings>=2.12.0",
    "torch==2.9.1", # Keep version fixed for flash-attn
    "transformers>=4.57.1",
    "pillow>=12.0.0",
    "torchvision>=0.24.1",
    "rich>=14.2.0",
    "python-multipart>=0.0.20",
    "ray[default]>=2.51.1",
    "pandas>=2.3.1",
    "mlflow>=3.6.0",
    "loguru>=0.7.3",
    "peft>=0.18.0",
    "bitsandbytes>=0.48.0",
]

[project.optional-dependencies]
# Training-specific dependencies (includes flash-attn)
training = [
    "dvc[s3]>=3.64.0",
    "flash-attn==2.8.3",
    "ray[data,train]>=2.51.1",
    "setuptools>=80.9.0",
    "accelerate>=1.10.0",
    "evaluate>=0.4.6",
    "datasets>=4.4.1",
    "rouge-score>=0.1.2",
    "hydra-core>=1.3.2",
    "psutil>=7.1.3",
    "nvidia-ml-py>=13.580.82",
    "pyrsmi>=1.0.0",
]

# Serving-specific dependencies
serving = [
    "fastapi>=0.116.1",
    "ray[serve]>=2.51.1",
]

[dependency-groups]
# Development dependencies (local-only)
dev = [
    "pre-commit>=4.3.0",
    "ruff>=0.12.8",
    "seaborn>=0.13.2",
    "wordcloud>=1.9.4",
]

test = [
    "pytest>=7.0.0",
    "pytest-cov>=4.0.0",
]

[tool.uv.extra-build-dependencies]
# Build dependencies for flash-attn compilation (recommended by uv team)
flash-attn = [{ requirement = "torch", match-runtime = true }]

# [tool.uv.extra-build-variables]
# Skip CUDA build during resolution, build at sync time
# flash-attn = { FLASH_ATTENTION_SKIP_CUDA_BUILD = "TRUE" }

[tool.uv]
concurrent-builds = 1  # Critical for flash-attn
concurrent-downloads = 8
concurrent-installs = 4
